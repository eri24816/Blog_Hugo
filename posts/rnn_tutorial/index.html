<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>PyTorch RNN Tutorial |
eri24816's blog</title><meta name=description content="[希望在大學的壓力下不要丟失我的初衷。<br/>那就是：我喜愛這個世界，所以想以最 high level 的角度理解世界，幫各種我喜歡的東西建立模型。例如音樂生成模型、style transfer、物理模擬。]"><meta name=author content><link rel=apple-touch-icon href=/apple-touch-icon.png sizes=180x180><link rel=icon href=/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/favicon-16x16.png sizes=16x16 type=image/png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#0c344b><link rel=icon href=/favicon.ico><link rel=stylesheet href=/dist/main.37ab3f61b95417873748.min.css><link rel=stylesheet href=/css/custom.css><link href="https://fonts.googleapis.com/css?family=Raleway" rel=stylesheet><link rel=stylesheet href=https://eri24816.github.io/styles.dc279fd0a61fc13f0a252b152bf04f164d339641553d05e1339933f0f3eed5d1.css><link rel=canonical href=https://eri24816.github.io/posts/rnn_tutorial/><meta property="og:title" content="PyTorch RNN Tutorial"><meta property="og:description" content="This tutorial will demonstrate how to build and train a simple RNN model with PyTorch."><meta property="og:type" content="article"><meta property="og:url" content="https://eri24816.github.io/posts/rnn_tutorial/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-03-09T12:54:18+08:00"><meta property="article:modified_time" content="2022-03-09T12:54:18+08:00"><meta itemprop=name content="PyTorch RNN Tutorial"><meta itemprop=description content="This tutorial will demonstrate how to build and train a simple RNN model with PyTorch."><meta itemprop=datePublished content="2022-03-09T12:54:18+08:00"><meta itemprop=dateModified content="2022-03-09T12:54:18+08:00"><meta itemprop=wordCount content="451"><meta itemprop=keywords content="Python,torch,"><meta name=twitter:card content="summary"><meta name=twitter:title content="PyTorch RNN Tutorial"><meta name=twitter:description content="This tutorial will demonstrate how to build and train a simple RNN model with PyTorch."><script src=https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js type=text/javascript></script></head><body><nav class="navbar navbar-expand-md navbar-light bg-light fixed-top shadow-sm" id=navbar-main-menu><div class=container><a class="navbar-brand font-weight-bold" href=https://eri24816.github.io/>eri24816's blog</a>
<a class="navbar-brand font-weight-bold" href=https://eri24816.github.io//categories/>Categories</a>
<a class="navbar-brand font-weight-bold" href=https://eri24816.github.io//tags/>Tags</a>
<a class="navbar-brand font-weight-bold" href=https://github.com/eri24816/eri24816.github.io>Source</a>
<a class="navbar-brand font-weight-bold" href=https://github.com/eri24816/>My github</a>
<a class="navbar-brand font-weight-bold" href=https://eri24816.github.io//posts/contact>Contact</a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#main-menu aria-controls=main-menu aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=main-menu><ul class="navbar-nav ml-auto"></ul></div></div></nav><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+='has-jax'})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><main class="content-page container pt-9 pb-5"><div class=row><div class=col><article><div class="row justify-content-center"><div class=col-lg-8><div class="meta text-muted mb-3"><p class="created text-muted text-uppercase font-weight-bold mb-1">March 9, 2022</p></div><a href=/categories/machine-learning>machine learning ></a><h1>PyTorch RNN Tutorial</h1></div></div><div class="row justify-content-center"><div class=col-lg-8><div class=content><p>This tutorial will demonstrate how to build and train a simple RNN model with PyTorch.</p><h2 id=concepts>Concepts</h2><h3 id=what-can-an-rnn-do>What can an RNN do?</h3><p>Given an input sequence $x=[x_1,x_2,\cdots,x_{n}]$, an RNN can generate a corresponding output sequence $\hat y=[\hat y_1,\hat y_2,\cdots,\hat y_{n}]$
successively. The strength of RNN is that it can &ldquo;remember&rdquo; its previosly seen input elements. When calculating $\hat y_i$, the model can access not only $x_i$ but also the information from $x_0$ to $x_{i-1}$, via its hidden state, $h_{i-1}$.</p><p><img src=https://i.imgur.com/lw62OZL.png#center alt=Image></p><h3 id=autoregressive-model>Autoregressive model</h3><p>Given the characteristics of an RNN, we can make it do something cool &ndash; predicting a sequence.</p><p>Imagine now we have a initial sequence [1,2,3,4,5] and feed it into an RNN. If the model is good at predicting linear sequences, it will predict some number near 6 as the next number, let&rsquo;s say 6.05.</p><p><img src=https://i.imgur.com/cCr0pSK.png alt=Image></p><p>Then we put the 6.05 back to the sequence, make it [1,2,3,4,5,6.05], and feed it into the model again. This time, the model says 7.02, so the sequence becomes [1,2,3,4,5,6.05,7.02]. As we repeat this process, the model can eventually generate a long sequence by itself.</p><p><img src=https://i.imgur.com/UhcKdwA.png alt=Image></p><p>To be precise, when training the model, we want it predict $x_{i+1}$ after seeing the input $[x_1, x_2, \cdots,x_{i}]$. That is, the difference between its output, $\hat y_i$, and the target output, $x_{i+1}$, should be minimized.</p><p><img src=https://i.imgur.com/jChTnLU.png#center alt=Image></p><p>We can define sequence $y =[ y_1, y_2,\cdots, y_{n}]$ as the target output, which $y_i = x_{i+1}$.</p><p>Thus, the loss function is the mean square error between $\hat y$ and $y$:</p><p>$$ \frac{1}{n}\sum_{i= 1}^{n}{(\hat y_i-x_{i+1})^2} = \frac{1}{n}\sum_{i= 1}^{n}{(\hat y_i-y_i)^2} = MSE(\hat y,y)$$.</p><h2 id=implementation>Implementation</h2><h3 id=1-import>1. Import</h3><p>Import the modules we will need.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> torch
<span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn
<span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</code></pre></div><h3 id=2-prepare-the-training-data>2. Prepare the training data</h3><p>First, we need the training data.
Here we generate a sine wave of $\sin(t)$, from $t=0$ to $t=80$, and sample peirod $=0.2$. Then a little noise is added to simulate sampling error.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sin(np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>80</span>,<span style=color:#ae81ff>0.2</span>))
data <span style=color:#f92672>+=</span> (np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random(data<span style=color:#f92672>.</span>shape)<span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span>)<span style=color:#f92672>*</span><span style=color:#ae81ff>0.2</span>
plt<span style=color:#f92672>.</span>plot(data)
</code></pre></div><p><img src=https://i.imgur.com/07PP9iu.jpg#centers alt=Image></p><p>By default, an RNN module require its input tensor to have the shape $[ Time, Batch, Feature ]$. To keep it simple, we can just set the
batch size and feature num to 1. So we have to expand the original data of size $[400]$ to $[ 400, 1,1 ]$ by doing unsqueeze(-1) twice.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>print(data<span style=color:#f92672>.</span>shape) <span style=color:#75715e>#(400,)</span>

<span style=color:#75715e># convert data into a torch tensor and expand the dimension of its shape</span>
data <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(data, dtype <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>float)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)

print(data<span style=color:#f92672>.</span>shape) <span style=color:#75715e># torch.Size([400, 1, 1])</span>
</code></pre></div><p>Get x and y that satisfy $y_i = x_{i+1}$.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e>#input sequence</span>
x <span style=color:#f92672>=</span> data[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]

<span style=color:#75715e># target output sequence</span>
y <span style=color:#f92672>=</span> data[<span style=color:#ae81ff>1</span>:]
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SimpleRNN</span>(nn<span style=color:#f92672>.</span>Module):
    <span style=color:#66d9ef>def</span> __init__(self):
        super()<span style=color:#f92672>.</span>__init__()
        self<span style=color:#f92672>.</span>rnn <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>RNN(<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>12</span>)
        self<span style=color:#f92672>.</span>linear <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>12</span>,<span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x, h_0 <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
        rnn_out, h_n <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>rnn(x, h_0)
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>linear(rnn_out), h_n
</code></pre></div></div><div class="tags my-3"><a class="badge badge-pill badge-light border mr-2" href=/tags/python><i class="fas fa-tag mr-2"></i>Python
</a><a class="badge badge-pill badge-light border mr-2" href=/tags/torch><i class="fas fa-tag mr-2"></i>torch</a></div><ul class="share nav my-3 justify-content-end"><li class=nav-item><a class=nav-link target=_blank href="https://twitter.com/intent/tweet?url=https%3a%2f%2feri24816.github.io%2fposts%2frnn_tutorial%2f&text=PyTorch%20RNN%20Tutorial"><i class="fa-fw fab fa-twitter"></i></a></li><li class=nav-item><a class=nav-link target=_blank href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2feri24816.github.io%2fposts%2frnn_tutorial%2f&title=PyTorch%20RNN%20Tutorial"><i class="fa-fw fab fa-linkedin-in"></i></a></li><li class=nav-item><a class=nav-link target=_blank href="https://www.facebook.com/sharer.php?u=https%3a%2f%2feri24816.github.io%2fposts%2frnn_tutorial%2f&t=PyTorch%20RNN%20Tutorial"><i class="fa-fw fab fa-facebook-f"></i></a></li><li class=nav-item><a class=nav-link target=_blank href="https://reddit.com/submit?url=https%3a%2f%2feri24816.github.io%2fposts%2frnn_tutorial%2f&title=PyTorch%20RNN%20Tutorial"><i class="fa-fw fab fa-reddit-alien"></i></a></li></nav></div></div><div class="row justify-content-center"><div class=col-lg-8></div></div></article></div></div><div class="related-content row mt-5 row-cols-1 row-cols-lg-3"><div class="col mb-3"><div class="card h-100"><a href=/posts/nnnode/ class=d-block><img src=https://i.imgur.com/sIUvHcq.jpg class="card-img-top mx-auto d-block" alt=NNNode><div class=card-body><h4 class=card-title>NNNode</h4><p class="card-text text-muted text-uppercase">November 17, 2021</p><div class=card-text>做NNNode的動機是我常常在用 Jupyter notebook 和 Pytorch train 神經網路的時候覺得很麻煩</div></div></a></div></div></div></main><footer class="footer text-center bg-dark py-6"><div class=container><div class=row><div class=col><ul class=list-inline></ul><p class=text-muted>Copyright &copy; eri24816's blog 2024</p><p class=text-muted>Powered by <a href=https://gohugo.io target=_blank>Hugo</a> with <a href=https://github.com/puresyntax71/hugo-theme-chunky-poster target=_blank>Chunky Poster</a>.</p></div></div></div></footer><script src=/dist/main.d608eadfe5ac0688902e.min.js></script><script src=/js/custom.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-WKQTFGNJW6"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-WKQTFGNJW6',{anonymize_ip:!1})}</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','G-WKQTFGNJW6','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>